{"cells":[{"metadata":{},"cell_type":"markdown","source":"**INTRODUCTION TO PYTHON: I WILL SHARE MY OWN EXPERIENCE HERE TO LEARN TOGETHER AND TEACH OTHER POEPLE.\n\n**"},{"metadata":{"_uuid":"3f64d7ba-2366-4ff3-8925-57923491d7dd","_cell_guid":"326062fa-d617-4e09-9b96-b5fc9a4a7418","trusted":true},"cell_type":"code","source":"\n\n\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns #data visualization\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\ndata = pd.read_csv(\"../input/pokemon-project/pokemon.csv\") #we used pandas library here to read dataset from csv file\n\ndata.info() # to see information about data\n\n#correlation map\n# to see and find relations between features in data we use correlation map\n#we will use seaborn library here to see on \"heatmap\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.corr() # to see correlation between features in data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation map\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()\n\n#we used \"heatmap\" feature from seaborn library here to make previous table heatmap here\n#check python seaborn library basics if you dont know how it works\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(10)\n#if you leave empty inside of pharantheses its gonna be first 5 data as default","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**1. INTRODUCTION TO PYTHON**"},{"metadata":{},"cell_type":"markdown","source":"In this project i will explain subject and then i will use that explaned subject with the example. for example i will use matplotlib library but before i left explanation about it.\n\nMATPLOTLIB\n\nMatplot is a python library that help us to plot data. The easiest and most basic plots are line, scatter and histogram plots.\n\nLine plot is better when x axis is time.\nScatter is better when there is correlation between two variables\nHistogram is better when we need to see distribution of numerical data.\nCustomization: Colors,labels,thickness of line, title, opacity, grid, figsize, ticks of axis and linestyle"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets start with the line plot in this instance\n\n# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.Speed.plot(kind = 'line', color = 'g',label = 'Speed',linewidth=1,alpha = 0.5,grid = True,linestyle = ':')\ndata.Defense.plot(color = 'r',label = 'Defense',linewidth=1, alpha = 0.5,grid = True,linestyle = '-.')\nplt.legend(loc='upper right')     # legend = puts label into plot\nplt.xlabel('x axis')              # label = name of label\nplt.ylabel('y axis')\nplt.title('Line Plot')            # title = title of plot\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Lets use scatter plot in this example\n\n# Scatter Plot \n# x = attack, y = defense\ndata.plot(kind='scatter', x='Attack', y='Defense',alpha = 0.5,color = 'red')\nplt.xlabel('Attack')              # label = name of label\nplt.ylabel('Defense')\nplt.title('Attack Defense Scatter Plot')            # title = title of plot\nplt.show()\n#if you dont use \"plt.show()\" end of the code you will also get this output: 'Text(0.5, 1.0, 'Attack Defense Scatter Plot')'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#And now lets use histogram plot in this example\n\n# Histogram\n# bins = number of bar in figure\ndata.Speed.plot(kind = 'hist',bins = 50,figsize = (12,12))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clf() = cleans it up again you can start a fresh\ndata.Speed.plot(kind = 'hist',bins = 50)\nplt.clf()\n# We cannot see plot due to clf()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**DICTIONARY**\n\nWhy do we need dictionary?\n\n* It has 'key' and 'value'\n* Faster than lists \n* What is key and value. Example:\n* dictionary = {'spain' : 'madrid'}\n* Key is spain.\n* Values is madrid. \n\nIt's that easy. \nLets practice some other properties like keys(), values(), update, add, check, remove key, remove all entries and remove dicrionary."},{"metadata":{"trusted":true},"cell_type":"code","source":"#create dictionary and look its keys and values\ndictionary = {'spain' : 'madrid','usa' : 'vegas'}\nprint(dictionary.keys())\nprint(dictionary.values())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Keys have to be immutable(duragan) objects like string, boolean, float, integer or tubles\n# List is not immutable\n# Keys are unique\ndictionary['spain'] = \"barcelona\"    # how to update existing entry\nprint(dictionary)\ndictionary['france'] = \"paris\"       # how to Add new entry\nprint(dictionary)\ndel dictionary['spain']              # how to remove entry with key 'spain'\nprint(dictionary)\nprint('france' in dictionary)        # how to check include or not\ndictionary.clear()                   # how to remove all entries in dict\nprint(dictionary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In order to run all code you need to take comment this line\ndel dictionary          # delete entire dictionary     \nprint(dictionary)       # it gives error because dictionary is deleted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PANDAS\n**\n\nWhat do we need to know about pandas?\n\nCSV: comma - separated values"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/pokemon-project/pokemon.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"series = data['Defense']        # data['Defense'] = series\nprint(type(series))\n\ndata_frame = data[['Defense']]  # data[['Defense']] = data frame\nprint(type(data_frame))\n\n\n#pandas 2 cesit data turunden olusuyor 1. si series 2. si data_frame(aslinda bir tane daha var ama kullanilmiyor o.)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data_frame)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(series)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DIFFERENCE BETWEEN SERIES AND DATA FRAME\n**\n\nSeries is a type of list in pandas which can take integer values, string values, double values and more. ... Series can only contain single list with index, whereas dataframe can be made of more than one series or we can say that a dataframe is a collection of series that can be used to analyse the data."},{"metadata":{},"cell_type":"markdown","source":"\nBefore continuing with pandas, we need to learn logic, control flow and filtering. \n\n* Comparison operator: ==, <, >, <= \n* Boolean operators: and, or ,not \n* Filtering pandas"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Comparison operator\nprint(3 > 2)\nprint(3!=2)\n# Boolean operators\nprint(True and False)# When you use \"and\" output will be false\nprint(True or False)# if you use \"or\" output will be the True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1 - Filtering Pandas data frame\nx = data['Defense']>200     # There are only 3 pokemons who have higher defense value than 200\n#if you wanna se as dataframe\ndata[x]#this gives you only true indexes\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2 - Filtering pandas with logical_and\n# There are only 2 pokemons who have higher defence value than 200 and higher attack value than 100\ndata[np.logical_and(data['Defense']>200, data['Attack']>100 )]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**WHILE and FOR LOOPS\n**\nLets learn the most basic while and for loops together."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay in loop if condition( i is not equal 5) is true\ni = 0\nwhile i != 5 :# until i is not equal to 5 increase the i(\"!= it means not equal\")\n    print('i is: ',i)\n    i +=1\nprint(i,' is equal to 5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Stay in loop if condition( i is not equal 5) is true\nlis = [1,2,3,4,5]\nfor i in lis:\n    print('i is: ',i)\nprint('')#alt alta yazdigimiz icin kodlar karismasin diye arala bosluk birakiyoruz(Turkish explanation)\n         #we leave a blank between codes to make view clean(English explanation)\n# Enumerate index and value of list(yani burada listenin indekslerine ulasmak istiyoruz enumurate o demek.)(0. index 1. index...)\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index, value in enumerate(lis):\n    print(index,\" : \",value)\nprint('')   \n\n# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'spain':'madrid','france':'paris'}\nfor key,value in dictionary.items():#dictionary_item bize hem key hem de value yi veriyor\n    print(key,\" : \",value)          #dictionary_item gives us key and value together\nprint('')\n\n# For pandas we can achieve index and value\nfor index,value in data[['Attack']][0:1].iterrows(): #[0:1] ile ilk elemani aliyoruz data icindeki 0 ile 1. index arasindaki yani\n                                                     #[0:1] it means youre taking firs value from data\n    print(index,\" : \",value)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this part, we learned:\n\n* how to import csv file\n* plotting line,scatter and histogram\n* basic dictionary features\n* basic pandas features like filtering that is actually something always used and main for being data scientist\n* While and for loops"},{"metadata":{},"cell_type":"markdown","source":"**2. PYTHON DATA SCIENCE TOOLBOX**"},{"metadata":{},"cell_type":"markdown","source":"USER DEFINED FUNCTION\nWhat we need to know about functions:\n\ndocstrings: documentation for functions. Example: \n\nfor f(): \n\n\"\"\"This is docstring for documentation of function f\"\"\"\n\ntuble: sequence of immutable python objects. \n\ncant modify values \n\ntuble uses paranthesis like tuble = (1,2,3) \n\nunpack tuble into several variables like a,b,c = tuble"},{"metadata":{"trusted":true},"cell_type":"code","source":"# example of what we learn above\ndef tuble_ex():\n    \"\"\" return defined t tuble\"\"\"\n    t = (1,2,3)\n    return t\na,b,c = tuble_ex()\nprint(a,b,c)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SCOPE\nWhat we need to know about scope:\n\nglobal: defined main body in script\n\nlocal: defined in a function\n\nbuilt in scope: names in predefined built in scope module such as print, len \n\nLets make some basic examples"},{"metadata":{"trusted":true},"cell_type":"code","source":"# guess print what\nx = 2\ndef f():\n    x = 3\n    return x\nprint(x)      # x = 2 global scope\nprint(f())    # x = 3 local scope","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# What if there is no local scope\nx = 5\ndef f():\n    y = 2*x        # there is no local scope x\n    return y\nprint(f())         # it uses global scope x\n# First local scopesearched, then global scope searched, if two of them cannot be found lastly built in scope searched.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How can we learn what is built in scope\nimport builtins\ndir(builtins)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nNESTED FUNCTION\n\nfunction inside function.\n\nThere is a LEGB rule that is search local scope, enclosing function, global and built in scopes, respectively."},{"metadata":{"trusted":true},"cell_type":"code","source":"#nested function\ndef square():\n    \"\"\" return square of value \"\"\"\n    def add():\n        \"\"\" add two local variable \"\"\"\n        x = 2\n        y = 3\n        z = x + y\n        return z\n    return add()**2\nprint(square())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"DEFAULT and FLEXIBLE ARGUMENTS\n\nDefault argument example: \ndef f(a, b=1):\n  \"\"\" b = 1 is default argument\"\"\"\n\n# default arguments\ndef f(a, b = 1, c = 2):\n    y = a + b + c\n    return y\nprint(f(5))\n# what if we want to change default arguments\nprint(f(5,4,3))Flexible argument example: \ndef f(*args):\n \"\"\" *args can be one or more\"\"\"\n\ndef f(** kwargs)\n \"\"\" **kwargs is a dictionary\"\"\"\n\n\nlets write some code to practice"},{"metadata":{"trusted":true},"cell_type":"code","source":"# default arguments\ndef f(a, b = 1, c = 2):\n    y = a + b + c\n    return y\nprint(f(5))\n# what if we want to change default arguments\nprint(f(5,4,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)\nprint(\"\")\nf(1,2,3,4)\n# flexible arguments **kwargs that is dictionary\ndef f(**kwargs):\n    \"\"\" print key and value of dictionary\"\"\"\n    for key, value in kwargs.items():               # If you do not understand this part turn for loop part and look at dictionary in for loop\n        print(key, \" \", value)\nf(country = 'spain', capital = 'madrid', population = 123456)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LAMBDA FUNCTION\n\nFaster way of writing function"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lambda function\nsquare = lambda x: x**2     # where x is name of argument\nprint(square(4))\ntot = lambda x,y,z: x+y+z   # where x,y,z are names of arguments\nprint(tot(1,2,3))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ANONYMOUS FUNCTİON\n\nLike lambda function but it can take more than one arguments.\n\n* map(func,seq) : applies a function to all the items in a list"},{"metadata":{"trusted":true},"cell_type":"code","source":"number_list = [1,2,3]\ny = map(lambda x:x**2,number_list)\nprint(list(y))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ITERATORS\n\niterable is an object that can return an iterator\n\niterable: an object with an associated iter() method \n\nexample: list, strings and dictionaries\n\niterator: produces next value with next() method"},{"metadata":{"trusted":true},"cell_type":"code","source":"# iteration example\nname = \"ronaldo\"\nit = iter(name)\nprint(next(it))    # print next iteration\nprint(*it)         # print remaining iteration","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# zip example\nlist1 = [1,2,3,4]\nlist2 = [5,6,7,8]\nz = zip(list1,list2)\nprint(z)\nz_list = list(z)\nprint(z_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"un_zip = zip(*z_list)\nun_list1,un_list2 = list(un_zip) # unzip returns tuble\nprint(un_list1)\nprint(un_list2)\nprint(type(un_list2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LIST COMPREHENSİON\n\nOne of the most important topic of this kernel \n\nWe use list comprehension for data analysis often. \n\nlist comprehension: collapse for loops for building lists into a single line \n\nEx: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. However it is unnecessarily long. We can make it one line code that is list comprehension."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of list comprehension\nnum1 = [1,2,3]\nnum2 = [i + 1 for i in num1 ]\nprint(num2)\n\n\"\"\"\n[i + 1 for i in num1 ]: list of comprehension \ni +1: list comprehension syntax \nfor i in num1: for loop syntax \ni: iterator \nnum1: iterable object\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conditionals on iterable\nnum1 = [5,10,15]\nnum2 = [i**2 if i == 10 else i-5 if i < 7 else i+5 for i in num1]\nprint(num2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets return pokemon csv and make one more list comprehension example\n# lets classify pokemons whether they have high or low speed. Our threshold is average speed.\nthreshold = sum(data.Speed)/len(data.Speed)\ndata[\"speed_level\"] = [\"high\" if i > threshold else \"low\" for i in data.Speed]\ndata.loc[:10,[\"speed_level\",\"Speed\"]] # we will learn loc more detailed later","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Up to now, we learned\n* User defined function\n* Scope\n* Nested function\n* Default and flexible arguments\n* Lambda function\n* Anonymous function\n* Iterators\n* List comprehension"},{"metadata":{},"cell_type":"markdown","source":"**3.CLEANING DATA**"},{"metadata":{},"cell_type":"markdown","source":"\n\nDIAGNOSE DATA for CLEANING\n\nWe need to diagnose and clean data before exploring. \n\nUnclean data:\n\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#We will use head, tail, columns, shape and info methods to diagnose data\n\ndata = pd.read_csv('../input/pokemon-project/pokemon.csv')\ndata.head()  # head shows first 5 rows","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tail shows last 5 rows\ndata.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# columns gives column names of features\ndata.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shape gives number of rows and columns in a tuble\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EXPLORATORY DATA ANALYSIS\n**\nvalue_counts(): Frequency counts \noutliers: the value that is considerably higher or lower from rest of the data\n\n* Lets say value at 75% is Q3 and value at 25% is Q1.\n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR \n* We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\nWhat is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in middle of the sequence. In this case it would be 11.\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above."},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example lets look frequency of pokemom types\nprint(data['Type 1'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemon","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example max HP is 255 or min defense is 5\ndata.describe() #ignore null entries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VISUAL EXPLORATORY DATA ANALYSIS\n**\n* Box plots: visualize basic statistics like outliers, min/max or quantiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Red line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column='Attack',by = 'Legendary')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\n**TIDY DATA**\n\nWe tidy data with melt(). Describing melt is confusing. Therefore lets make example to understand it."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['Attack','Defense'])\nmelted","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PIVOTING DATA\n**\n\nReverse of melting."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'Name', columns = 'variable',values='value')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CONCATENATING DATA\n**\n\nWe can concatenate two dataframe"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data['Attack'].head()\ndata2= data['Defense'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 0 : adds dataframes in row\nconc_data_col","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**DATA TYPES\n**\n\nThere are 5 basic data types: object(string),booleab, integer, float and categorical. \nWe can make conversion data types like from str to categorical or from int to float \nWhy is category important:\n\n* make dataframe smaller in memory\n* can be utilized for anlaysis especially for sklear(we will learn later)"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets convert object(str) to categorical and int to float.\ndata['Type 1'] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# As you can see Type 1 is converted from object to categorical\n# And Speed ,s converted from int to float\ndata.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MISSING DATA and TESTING WITH ASSERT\n**\n\nIf we encounter with missing data, what we can do:\n\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean \n* Assert statement: check that you can turn on or turn off when you are done with your testing of the program\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets look at does pokemon data have nan value\n# As you can see there are 800 entries. However Type 2 has 414 non-null object so it has 386 null object.\ndata.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets chech Type 2\ndata[\"Type 2\"].value_counts(dropna =False)\n# As you can see, there are 386 NAN value","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets drop nan values\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1[\"Type 2\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In order to run all code, we need to make this line comment\n# assert 1==2 # return error because it is false","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert  data['Type 2'].notnull().all() # returns nothing because we drop nan values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"Type 2\"].fillna('empty',inplace = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert  data['Type 2'].notnull().all() # returns nothing because we do not have nan values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # With assert statement we can check a lot of thing. For example\n# assert data.columns[1] == 'Name'\n# assert data.Speed.dtypes == np.int","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In this part, we learn:\n\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert"},{"metadata":{},"cell_type":"markdown","source":"**4. PANDAS FOUNDATION**\n\n**REVIEW of PANDAS\n**\n\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\nsingle column = series\nNaN = not a number\ndataframe.values = numpy\n\n\n**BUILDING DATA FRAMES FROM SCRATCH\n**\n\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n* zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data frames from dictionary\ncountry = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add new columns\ndf[\"capital\"] = [\"madrid\",\"paris\"]\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Broadcasting\ndf[\"income\"] = 0 #Broadcasting entire column\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**VISUAL EXPLORATORY DATA ANALYSIS\n**\n\n* Plot\n* Subplot\n* Histogram:\n    *bins: number of bins\n    *range(tuble): min and max values of bins\n    *normed(boolean): normalize or not\n    *cumulative(boolean): compute cumulative distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting all data \ndata1 = data.loc[:,[\"Attack\",\"Defense\",\"Speed\"]]\ndata1.plot()\n# it is confusing","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# subplots\ndata1.plot(subplots = True)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"Attack\",y = \"Defense\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# hist plot  \ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**STATISTICAL EXPLORATORY DATA ANALYSIS\n**\n\nI already explained it at previous parts. However lets look at one more time.\n\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**INDEXING PANDAS TIME SERIES\n**\n\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format"},{"metadata":{"trusted":true},"cell_type":"code","source":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n# In order to practice lets take head of pokemon data and add it a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**RESAMPLING PANDAS TIME SERIES\n**\n\nResampling: statistical method over different time intervals\nNeeds string to specify frequency like \"M\" = month or \"A\" = year\nDownsampling: reduce date time rows to slower frequency like from daily to weekly\nUpsampling: increase date time rows to faster frequency like from daily to hourly\nInterpolate: Interpolate values according to different methods like ‘linear’, ‘time’ or index’\nhttps://pandas.pydata.org/pandas-docs/stable/generated/pandas.Series.interpolate.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MANIPULATING DATA FRAMES WITH PANDAS\n**\n\n**INDEXING DATA FRAMES**\n\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns\n* "},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data\ndata = pd.read_csv('../input/pokemon-project/pokemon.csv')\ndata= data.set_index(\"#\")\ndata.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# indexing using square brackets\ndata[\"HP\"][1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using column attribute and row label\ndata.HP[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using loc accessor\ndata.loc[1,[\"HP\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecting only some columns\ndata[[\"HP\",\"Attack\"]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**SLICING DATA FRAME\n**\n\n* Difference between selecting columns\n* Series and data frames\n* Slicing and indexing series\n* Reverse slicing\n* From something to end"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"HP\"]))     # series\nprint(type(data[[\"HP\"]]))   # data frames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Slicing and indexing series\ndata.loc[1:10,\"HP\":\"Defense\"]   # 10 and \"Defense\" are inclusive","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reverse slicing \ndata.loc[10:1:-1,\"HP\":\"Defense\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# From something to end\ndata.loc[1:10,\"Speed\":]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**FILTERING DATA FRAMES\n**\n\nCreating boolean series Combining filters Filtering column based others"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating boolean series\nboolean = data.HP > 200\ndata[boolean]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Combining filters\nfirst_filter = data.HP > 150\nsecond_filter = data.Speed > 35\ndata[first_filter & second_filter]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filtering column based others\ndata.HP[data.Speed<15]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**TRANSFORMING DATA\n**\n\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plain python functions\ndef div(n):\n    return n/2\ndata.HP.apply(div)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can use lambda function\ndata.HP.apply(lambda n : n/2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Defining column using other columns\ndata[\"total_power\"] = data.Attack + data.Defense\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**INDEX OBJECTS AND LABELED DATA\n**\n\nindex: sequence of label"},{"metadata":{"trusted":true},"cell_type":"code","source":"# our index name is this:\nprint(data.index.name)\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,900,1)\ndata3.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can make one of the column as index. I actually did it at the beginning of manipulating data frames with pandas section\n# It was like this\n# data= data.set_index(\"#\")\n# also you can use \n# data.index = data[\"#\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**HIERARCHICAL INDEXING\n**\n\nSetting indexing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv(\"../input/pokemon-project/pokemon.csv\")\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"Type 1\",\"Type 2\"]) \ndata1.head(100)\n# data1.loc[\"Fire\",\"Flying\"] # howw to use indexes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**PIVOTING DATA FRAMES\n**\n\npivoting: reshape tool"},{"metadata":{"trusted":true},"cell_type":"code","source":"dic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pivoting\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n\nSTACKING and UNSTACKING DATAFRAME\n\n\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position"},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n# lets unstack it","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# level determines indexes\ndf1.unstack(level=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.unstack(level=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MELTING DATA FRAMES\n**\n\n* Reverse of pivoting"},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**ATEGORICALS AND GROUPBY**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# We will use df\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation / reduction method\n# there are other methods like sum, std,max or min","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}